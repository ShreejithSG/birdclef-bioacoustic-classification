{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-21T05:06:53.321239Z",
     "iopub.status.busy": "2025-04-21T05:06:53.320755Z",
     "iopub.status.idle": "2025-04-21T05:06:53.615417Z",
     "shell.execute_reply": "2025-04-21T05:06:53.614897Z",
     "shell.execute_reply.started": "2025-04-21T05:06:53.321212Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T05:06:59.818114Z",
     "iopub.status.busy": "2025-04-21T05:06:59.817459Z",
     "iopub.status.idle": "2025-04-21T05:07:03.842151Z",
     "shell.execute_reply": "2025-04-21T05:07:03.841553Z",
     "shell.execute_reply.started": "2025-04-21T05:06:59.818088Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Downloading & Precprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T05:07:26.913173Z",
     "iopub.status.busy": "2025-04-21T05:07:26.912865Z",
     "iopub.status.idle": "2025-04-21T05:07:27.206705Z",
     "shell.execute_reply": "2025-04-21T05:07:27.206078Z",
     "shell.execute_reply.started": "2025-04-21T05:07:26.913149Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T05:07:28.592992Z",
     "iopub.status.busy": "2025-04-21T05:07:28.592699Z",
     "iopub.status.idle": "2025-04-21T05:07:29.292656Z",
     "shell.execute_reply": "2025-04-21T05:07:29.291893Z",
     "shell.execute_reply.started": "2025-04-21T05:07:28.592968Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "birdclef_2025_path = kagglehub.competition_download('birdclef-2025')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T05:07:30.386108Z",
     "iopub.status.busy": "2025-04-21T05:07:30.385367Z",
     "iopub.status.idle": "2025-04-21T05:07:31.237032Z",
     "shell.execute_reply": "2025-04-21T05:07:31.236275Z",
     "shell.execute_reply.started": "2025-04-21T05:07:30.386072Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import librosa\n",
    "\n",
    "# Base path from kagglehub\n",
    "birdclef_2025_path = kagglehub.competition_download('birdclef-2025')\n",
    "audio_dir = os.path.join(birdclef_2025_path, \"train_audio\")\n",
    "csv_path = os.path.join(birdclef_2025_path, \"train.csv\")\n",
    "\n",
    "# Constants\n",
    "SAMPLE_RATE = 32000\n",
    "DURATION = 5\n",
    "N_MELS = 128\n",
    "FREQ_MAX = 16000\n",
    "AUDIO_LEN = SAMPLE_RATE * DURATION\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Audio to Log-Mel Spectrogram\n",
    "\n",
    "This function takes an audio file path and returns its log-mel spectrogram representation:\n",
    "\n",
    "- Loads the audio at 32kHz sampling rate\n",
    "- Pads or trims to 5 seconds (exact length)\n",
    "- Computes the mel spectrogram with `n_mels` bands (default 128)\n",
    "- Converts it to log scale (decibels) using `librosa.power_to_db`\n",
    "- Returns a `(n_mels, time)` shaped matrix used as CNN input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T05:07:33.854254Z",
     "iopub.status.busy": "2025-04-21T05:07:33.853494Z",
     "iopub.status.idle": "2025-04-21T05:07:33.858920Z",
     "shell.execute_reply": "2025-04-21T05:07:33.858062Z",
     "shell.execute_reply.started": "2025-04-21T05:07:33.854226Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_log_mel(filepath):\n",
    "    y, sr = librosa.load(filepath, sr=SAMPLE_RATE)\n",
    "    if len(y) < AUDIO_LEN:\n",
    "        y = np.pad(y, (0, AUDIO_LEN - len(y)))\n",
    "    else:\n",
    "        y = y[:AUDIO_LEN]\n",
    "    \n",
    "    mel = librosa.feature.melspectrogram(\n",
    "        y=y, sr=sr, n_mels=N_MELS, fmax=FREQ_MAX\n",
    "    )\n",
    "    log_mel = librosa.power_to_db(mel, ref=np.max)\n",
    "    return log_mel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading\n",
    "Loaded training audio files from `train_audio/` and metadata from `train.csv`. Only high-quality clips were used (rating ‚â• 4).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T05:07:36.025356Z",
     "iopub.status.busy": "2025-04-21T05:07:36.025076Z",
     "iopub.status.idle": "2025-04-21T05:07:36.030008Z",
     "shell.execute_reply": "2025-04-21T05:07:36.029150Z",
     "shell.execute_reply.started": "2025-04-21T05:07:36.025334Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class BirdLogMelDataset(Dataset):\n",
    "    def __init__(self, filepaths, labels):\n",
    "        self.filepaths = filepaths\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filepaths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        log_mel = load_log_mel(self.filepaths[idx])\n",
    "        log_mel = np.expand_dims(log_mel, axis=0)  # (1, 128, time)\n",
    "        return torch.tensor(log_mel, dtype=torch.float32), torch.tensor(self.labels[idx], dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† BirdCNN ‚Äì Simple Binary Classifier\n",
    "\n",
    "- Takes a log-mel spectrogram as input (1 √ó 128 √ó time)\n",
    "- 3 convolution layers with ReLU + pooling\n",
    "- Uses global average pooling to reduce size\n",
    "- Final layer gives 1 probability (bird present or not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T05:07:38.044653Z",
     "iopub.status.busy": "2025-04-21T05:07:38.044316Z",
     "iopub.status.idle": "2025-04-21T05:07:38.049623Z",
     "shell.execute_reply": "2025-04-21T05:07:38.048844Z",
     "shell.execute_reply.started": "2025-04-21T05:07:38.044633Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class BirdCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T05:10:45.932831Z",
     "iopub.status.busy": "2025-04-21T05:10:45.932281Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for: grekis\n",
      "Done Loading\n",
      "Done Model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22bb53ef5dad4d7488b2b7c686a86274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b50c776a1c824cc89f67a002263aa16a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70ed117433844970a0a7c621c9ae6547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for: compau\n",
      "Done Loading\n",
      "Done Model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b57bca7493a945ab9142e6d7844c1a86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "219faf6ea405457b920c2d1e79fa8b57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a8aa61568c8488e9957f1c5f656a74a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for: trokin\n",
      "Done Loading\n",
      "Done Model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d24cac66d8e4bd587968d7a046167e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afad7d45168449baa65cc08d29d08cd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "785bd6d33c994f7faca1f1102733e0c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for: roahaw\n",
      "Done Loading\n",
      "Done Model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89931946961b4312babc19488a123d45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07dae9ebdf2b46089f3a5cfb836da916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38b50e1e3eef4637a2bed635edd28112",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for: banana\n",
      "Done Loading\n",
      "Done Model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6498ccabacea4b3790ca946f7a141754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fbef2b4ea434c488404b8fce5d5b0db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f3408aa9c584a1198fe38ea6046f881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for: whtdov\n",
      "Done Loading\n",
      "Done Model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "806fe73e3ee94d6fa0c3b0e1944acf5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19d4f7aa8d5d4bbb86baa60ba8e0d3f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7efbbf6281524f3b95cbeb1ed0d936dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for: socfly1\n",
      "Done Loading\n",
      "Done Model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9998e66a546349759094d5e14012e055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94797c4086b847a6b8c16072de33bb78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "501f647ddf4f4256a2f0266881975abd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for: yeofly1\n",
      "Done Loading\n",
      "Done Model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd2df5c48780454a89d0c1bd15e0c8e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tqdm.notebook as tqdm\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Choose top-N most common species to demo\n",
    "top_species = df[\"primary_label\"].value_counts().index[:10]\n",
    "models = {}\n",
    "\n",
    "for bird in top_species:\n",
    "    print(f\"Training model for: {bird}\")\n",
    "\n",
    "    # Positive = bird, Negative = others (same size)\n",
    "    pos_df = df[df[\"primary_label\"] == bird]\n",
    "    neg_df = df[df[\"primary_label\"] != bird].sample(len(pos_df))\n",
    "\n",
    "    combined_df = pd.concat([pos_df, neg_df])\n",
    "    labels = (combined_df[\"primary_label\"] == bird).astype(int).values\n",
    "    filepaths = [os.path.join(audio_dir, fname) for fname in combined_df[\"filename\"]]\n",
    "\n",
    "    print(\"Done Loading\")\n",
    "    # Train/val split\n",
    "    train_fp, val_fp, train_labels, val_labels = train_test_split(\n",
    "        filepaths, labels, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    train_ds = BirdLogMelDataset(train_fp, train_labels)\n",
    "    val_ds = BirdLogMelDataset(val_fp, val_labels)\n",
    "    train_dl = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "    val_dl = DataLoader(val_ds, batch_size=16)\n",
    "\n",
    "    # Model init\n",
    "    model = BirdCNN().to(DEVICE)\n",
    "    loss_fn = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    print(\"Done Model\")\n",
    "    # Training\n",
    "    for epoch in range(3):  # Increase this for better performance\n",
    "        model.train()\n",
    "        for x, y in tqdm.tqdm(train_dl):\n",
    "            x, y = x.to(DEVICE), y.to(DEVICE).unsqueeze(1)\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(x)\n",
    "            loss = loss_fn(preds, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    models[bird] = model\n",
    "    torch.save(model.state_dict(), f\"{bird}_logmel_cnn.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T05:36:16.827792Z",
     "iopub.status.busy": "2025-04-21T05:36:16.827282Z",
     "iopub.status.idle": "2025-04-21T05:36:16.831338Z",
     "shell.execute_reply": "2025-04-21T05:36:16.830656Z",
     "shell.execute_reply.started": "2025-04-21T05:36:16.827766Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T05:36:31.583104Z",
     "iopub.status.busy": "2025-04-21T05:36:31.582314Z",
     "iopub.status.idle": "2025-04-21T05:36:31.587939Z",
     "shell.execute_reply": "2025-04-21T05:36:31.587209Z",
     "shell.execute_reply.started": "2025-04-21T05:36:31.583063Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x = x.to(DEVICE)\n",
    "            preds = model(x).cpu().numpy().flatten()\n",
    "            preds = (preds > 0.5).astype(int)\n",
    "            all_preds.extend(preds)\n",
    "            all_targets.extend(y.numpy())\n",
    "\n",
    "    return f1_score(all_targets, all_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "    train_f1 = evaluate_model(model, train_dl)\n",
    "    val_f1 = evaluate_model(model, val_dl)\n",
    "    \n",
    "    print(f\"F1 Score - Train: {train_f1:.4f}, Val: {val_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéôÔ∏è Feature Extraction: MFCC\n",
    "\n",
    "We use **Mel-Frequency Cepstral Coefficients (MFCCs)** as audio features for training.\n",
    "\n",
    "- MFCCs capture the **timbre and texture** of sounds, making them useful for identifying bird calls.\n",
    "- The audio is resampled to 32 kHz and clipped or padded to 5 seconds.\n",
    "- From this, we extract **40 MFCC coefficients** across time.\n",
    "- The MFCCs are then normalized to have zero mean and unit variance, which helps training.\n",
    "\n",
    "This gives us a **feature map of shape (40, time)** for each audio clip.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_mfcc(filepath):\n",
    "    y, sr = librosa.load(filepath, sr=SAMPLE_RATE)\n",
    "    \n",
    "    if len(y) < AUDIO_LEN:\n",
    "        y = np.pad(y, (0, AUDIO_LEN - len(y)))\n",
    "    else:\n",
    "        y = y[:AUDIO_LEN]\n",
    "    \n",
    "    mfcc = librosa.feature.mfcc(\n",
    "        y=y,\n",
    "        sr=sr,\n",
    "        n_mfcc=N_MFCC,          # e.g., 40\n",
    "        n_fft=2048,\n",
    "        hop_length=512,\n",
    "        fmax=FREQ_MAX\n",
    "    )\n",
    "    \n",
    "    # Optional: Normalize MFCC\n",
    "    mfcc = (mfcc - np.mean(mfcc)) / (np.std(mfcc) + 1e-6)\n",
    "    \n",
    "    return mfcc  # Shape: (n_mfcc, time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "N_MFCC = 40       # Can experiment with 13, 20, 40, etc.\n",
    "SAMPLE_RATE = 32000\n",
    "AUDIO_LEN = 5 * SAMPLE_RATE\n",
    "FREQ_MAX = 16000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_mfcc_logmel(filepath):\n",
    "    y, sr = librosa.load(filepath, sr=SAMPLE_RATE)\n",
    "\n",
    "    if len(y) < AUDIO_LEN:\n",
    "        y = np.pad(y, (0, AUDIO_LEN - len(y)))\n",
    "    else:\n",
    "        y = y[:AUDIO_LEN]\n",
    "    \n",
    "    # Log-Mel Spectrogram\n",
    "    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=N_MELS, fmax=FREQ_MAX)\n",
    "    log_mel = librosa.power_to_db(mel, ref=np.max)\n",
    "\n",
    "    # MFCC\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=N_MFCC, fmax=FREQ_MAX)\n",
    "    \n",
    "    # Normalize both (optional but recommended)\n",
    "    log_mel = (log_mel - np.mean(log_mel)) / (np.std(log_mel) + 1e-6)\n",
    "    mfcc = (mfcc - np.mean(mfcc)) / (np.std(mfcc) + 1e-6)\n",
    "    \n",
    "    # Ensure same time dimension\n",
    "    min_time = min(log_mel.shape[1], mfcc.shape[1])\n",
    "    log_mel = log_mel[:, :min_time]\n",
    "    mfcc = mfcc[:, :min_time]\n",
    "\n",
    "    # Stack as 2-channel input: shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.tensor(x).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class BirdCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(2, 16, 3, padding=1),  # üîÅ Changed input channels: 1 ‚Üí 2\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ MFCC + Log-Mel Combined Input\n",
    "\n",
    "Instead of using just log-mel or MFCC, we stack both as a 2-channel input:\n",
    "\n",
    "- Channel 0: Log-Mel Spectrogram (128 √ó time)\n",
    "- Channel 1: MFCC (40 √ó time)\n",
    "\n",
    "This gives the model both spectral texture and timbral detail. The CNN is updated to accept 2 input channels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 11361821,
     "sourceId": 91844,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
