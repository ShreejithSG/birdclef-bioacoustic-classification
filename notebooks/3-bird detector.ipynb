{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91844,"databundleVersionId":11361821,"isSourceIdPinned":false,"sourceType":"competition"}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport librosa\nimport soundfile as sf\nfrom tqdm import tqdm\nfrom sklearn.utils import resample\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import f1_score, roc_auc_score\nfrom xgboost import XGBClassifier\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Settings\nAUDIO_BASE = \"/kaggle/input/birdclef-2025/train_audio/\"\ndf = pd.read_csv(\"/kaggle/input/birdclef-2025/train.csv\")\ntop10 = ['grekis', 'compau', 'trokin', 'roahaw', 'banana', 'whtdov', 'socfly1', 'yeofly1', 'bobfly1', 'wbwwre1']\ntarget_birds = ['grekis', 'compau', 'trokin']\nmodels = {}\n\n# Main loop\nfor bird in target_birds:\n    print(f\"\\n==================== üê¶ Training for '{bird}' ====================\")\n\n    # Create labels\n    pos_df = df[df['primary_label'] == bird].copy()\n    pos_df['label'] = 1\n    neg_df = df[df['primary_label'].isin(top10) & (df['primary_label'] != bird)].copy()\n    neg_df['label'] = 0\n\n    # Balance\n    neg_df_balanced = resample(neg_df, replace=False, n_samples=min(len(pos_df), len(neg_df)), random_state=42)\n    combined_df = pd.concat([pos_df, neg_df_balanced]).sample(frac=1, random_state=42)\n\n    X, y = [], []\n\n    for _, row in tqdm(combined_df.iterrows(), total=len(combined_df), desc=f\"Extracting {bird}\"):\n        full_path = os.path.join(AUDIO_BASE, row['filename'])\n        try:\n            y_raw, sr = sf.read(full_path)\n            samples_per_chunk = sr * 5\n            num_chunks = len(y_raw) // samples_per_chunk\n            if num_chunks == 0:\n                continue\n\n            chunk_features = []\n            for i in range(num_chunks):\n                chunk = y_raw[i*samples_per_chunk : (i+1)*samples_per_chunk]\n                S = librosa.stft(chunk, n_fft=1024, hop_length=512)\n                S_db = librosa.power_to_db(np.abs(S)**2, ref=np.max)\n                freqs = librosa.fft_frequencies(sr=sr, n_fft=1024)\n                bin_edges = np.linspace(0, 16000, 3201)\n                binary_vector = np.zeros(3200, dtype=int)\n                energy_per_freq = S_db.max(axis=1)\n                adaptive_threshold = np.percentile(energy_per_freq, 76.7)\n\n                for j in range(3200):\n                    bin_mask = (freqs >= bin_edges[j]) & (freqs < bin_edges[j+1])\n                    if np.any(bin_mask) and np.max(energy_per_freq[bin_mask]) > adaptive_threshold:\n                        binary_vector[j] = 1\n\n                chunk_features.append(binary_vector)\n\n            # Aggregate chunks\n            median_vector = np.median(np.array(chunk_features), axis=0)\n            final_vector = (median_vector > 0.5).astype(int)\n\n            X.append(final_vector)\n            y.append(row['label'])\n\n        except Exception as e:\n            print(f\"‚ùå {row['filename']} failed: {e}\")\n\n    # Final dataset\n    X = np.stack(X)\n    y = np.array(y)\n\n    # Train with Stratified 5-Fold CV\n    f1s, aucs = [], []\n    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\n    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n        X_train, X_val = X[train_idx], X[val_idx]\n        y_train, y_val = y[train_idx], y[val_idx]\n\n        clf = XGBClassifier(\n            n_estimators=500,\n            scale_pos_weight=(len(y_train) - sum(y_train)) / sum(y_train),\n            use_label_encoder=False,\n            eval_metric='logloss',\n            random_state=42\n        )\n\n        clf.fit(X_train, y_train)\n        y_proba = clf.predict_proba(X_val)[:, 1]\n        y_pred = (y_proba > 0.5).astype(int)\n\n        f1s.append(f1_score(y_val, y_pred))\n        aucs.append(roc_auc_score(y_val, y_proba))\n\n    print(f\"üìä {bird} | Avg F1 Score: {np.mean(f1s):.4f} | Avg AUC-ROC: {np.mean(aucs):.4f}\")\n    models[bird] = clf","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport librosa\nimport numpy as np\nimport pandas as pd\n\n# Paths\nAUDIO_BASE_TEST = '/kaggle/input/birdclef-2025/test_soundscapes/'\nclass_labels = sorted(os.listdir('/kaggle/input/birdclef-2025/train_audio/'))  # All 206 birds\n\n# Submission storage\nsubmission_rows = []\n\n# Loop over test soundscapes\ntest_files = sorted([f for f in os.listdir(AUDIO_BASE_TEST) if f.endswith('.ogg')])\nfor file in test_files:\n    full_path = os.path.join(AUDIO_BASE_TEST, file)\n    signal, sr = librosa.load(full_path, sr=32000)\n    samples_per_chunk = sr * 5\n\n    for i in range(0, len(signal), samples_per_chunk):\n        chunk = signal[i:i+samples_per_chunk]\n        if len(chunk) < samples_per_chunk:\n            continue  # skip short ones\n\n        try:\n            # Binary feature extraction\n            S = librosa.stft(chunk, n_fft=1024, hop_length=512)\n            S_power = np.abs(S) ** 2\n            S_db = librosa.power_to_db(S_power, ref=np.max)\n            freqs = librosa.fft_frequencies(sr=sr, n_fft=1024)\n            bin_edges = np.linspace(0, 16000, 3201)\n            binary_vector = np.zeros(3200, dtype=int)\n            energy_per_freq = S_db.max(axis=1)\n            adaptive_threshold = np.percentile(energy_per_freq, 76.7)\n\n            for j in range(3200):\n                bin_mask = (freqs >= bin_edges[j]) & (freqs < bin_edges[j+1])\n                if np.any(bin_mask) and np.max(energy_per_freq[bin_mask]) > adaptive_threshold:\n                    binary_vector[j] = 1\n\n            # Predict with models\n            row_id = file.replace(\".ogg\", \"\") + f\"_{(i//samples_per_chunk+1)*5}\"\n            row = [row_id]\n\n            for bird in class_labels:\n                if bird in models:\n                    prob = models[bird].predict_proba(binary_vector.reshape(1, -1))[:, 1][0]\n                    row.append(prob)\n                else:\n                    row.append(0.001)  # default prob for birds you didn‚Äôt train\n\n            submission_rows.append(row)\n\n        except Exception as e:\n            print(f\"‚ùå Error processing chunk from {file}: {e}\")\n\n# Save submission\nsubmission_df = pd.DataFrame(submission_rows, columns=['row_id'] + class_labels)\nsubmission_df.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}