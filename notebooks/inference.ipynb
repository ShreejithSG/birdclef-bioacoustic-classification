{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":91844,"databundleVersionId":11361821,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":11974597,"sourceType":"datasetVersion","datasetId":7530400}],"dockerImageVersionId":31041,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport librosa\nimport numpy as np\nimport pandas as pd\nimport joblib\nfrom tqdm import tqdm\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Set configs\nsr = 32000\nchunk_duration = 5  # seconds\nn_mels = 128\nperc_threshold = 90.0\n\n# Paths\nMODEL_PATH = \"/kaggle/input/206-bird-detector/birdclef_models.joblib\"\nAUDIO_BASE_TEST = \"/kaggle/input/birdclef-2025/test_soundscapes/\"\nAUDIO_BASE_TRAIN = \"/kaggle/input/birdclef-2025/train_audio/\"\n\n# Load class labels\nclass_labels = sorted(os.listdir(AUDIO_BASE_TRAIN))\n\n# Load models\nprint(\"📦 Loading trained models...\")\nmodels = joblib.load(MODEL_PATH)\nprint(f\"✅ Loaded {len(models)} species models\")\n\n# Get test soundscape files\ntry:\n    test_files = sorted([f for f in os.listdir(AUDIO_BASE_TEST) if f.endswith(\".ogg\")])\nexcept:\n    test_files = []\n\n# If test files not visible (e.g. local run), simulate with train audio\nif len(test_files) == 0:\n    print(\"⚠️ No test files found. Simulating with 3 train samples...\")\n    test_files = []\n    for bird in class_labels[:3]:\n        species_dir = os.path.join(AUDIO_BASE_TRAIN, bird)\n        for f in os.listdir(species_dir):\n            if f.endswith(\".ogg\") or f.endswith(\".mp3\"):\n                test_files.append(os.path.join(species_dir, f))\n                break\nelse:\n    test_files = [os.path.join(AUDIO_BASE_TEST, f) for f in test_files]\n\n# Feature extraction\ndef extract_chunk_features(y):\n    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels, power=2.0)\n    mel_db = librosa.power_to_db(mel, ref=np.max)\n    band_means = mel_db.mean(axis=1)\n    band_stds = mel_db.std(axis=1)\n    thresh = np.percentile(mel, perc_threshold)\n    mask = (mel > thresh)\n    frac_active = mask.sum(axis=1) / mask.shape[1]\n    return np.concatenate([band_means, band_stds, frac_active])\n\n# Inference\nsubmission_rows = []\n\nfor file_path in tqdm(test_files, desc=\"🔊 Running inference\"):\n    try:\n        y, _ = librosa.load(file_path, sr=sr)\n    except Exception as e:\n        print(f\"❌ Failed to load {file_path}: {e}\")\n        continue\n\n    samples_per_chunk = sr * chunk_duration\n    num_chunks = len(y) // samples_per_chunk\n\n    for i in range(num_chunks):\n        chunk = y[i*samples_per_chunk : (i+1)*samples_per_chunk]\n        if len(chunk) < samples_per_chunk:\n            continue\n\n        try:\n            feat = extract_chunk_features(chunk)\n        except Exception as e:\n            print(f\"❌ Feature extraction failed: {e}\")\n            continue\n\n        # Build row_id\n        base_name = os.path.basename(file_path).replace(\".ogg\", \"\").replace(\".mp3\", \"\")\n        row_id = base_name + f\"_{(i+1)*chunk_duration}\"\n        row = [row_id]\n\n        # Predict for all 206 birds\n        for bird in class_labels:\n            model = models.get(bird)\n            try:\n                prob = model.predict_proba(feat.reshape(1, -1))[:, 1][0] if model else 0.001\n            except Exception:\n                prob = 0.001\n            row.append(prob)\n\n        submission_rows.append(row)\n\n# Final dataframe\nsubmission_df = pd.DataFrame(submission_rows, columns=[\"row_id\"] + class_labels)\nsubmission_df.to_csv(\"submission.csv\", index=False)\nprint(\"✅ submission.csv saved!\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-27T18:58:23.083962Z","iopub.execute_input":"2025-05-27T18:58:23.084752Z","iopub.status.idle":"2025-05-27T18:58:39.371922Z","shell.execute_reply.started":"2025-05-27T18:58:23.084714Z","shell.execute_reply":"2025-05-27T18:58:39.371163Z"}},"outputs":[{"name":"stdout","text":"📦 Loading trained models...\n✅ Loaded 206 species models\n⚠️ No test files found. Simulating with 3 train samples...\n","output_type":"stream"},{"name":"stderr","text":"🔊 Running inference: 100%|██████████| 3/3 [00:14<00:00,  4.70s/it]","output_type":"stream"},{"name":"stdout","text":"✅ submission.csv saved!\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":2}]}